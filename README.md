# Acumen Chat

A modern AI chat application built with Next.js, Tailwind CSS, and shadcn/ui. This application allows you to chat with various AI models from different providers, manage your API keys, and save your chat history locally.

## Features

- ğŸ’¬ Chat with multiple AI models from OpenAI, Anthropic, Google, Mistral, and other providers
- ğŸ” Bring your own API keys with local storage
- ğŸ›ï¸ Support for custom models and OpenAI-compatible endpoints
- ğŸ’¾ Local storage for chat history and settings
- âš¡ Real-time streaming responses
- ğŸ”„ Multiple response versions and regeneration capabilities
- ğŸ¨ Modern UI with Tailwind CSS and shadcn/ui
- ğŸ“± Responsive design for desktop and mobile

## Planned Features

- ğŸ“š File upload and document analysis capabilities
- ğŸ§  Knowledge management with personal knowledge base and RAG support
- ğŸ”„ Synchronization across devices with cloud storage
- ğŸ“¤ Export chats to PDF or markdown files
- ğŸ”— Integration with external tools and MCP
- ğŸ“‹ Advanced prompt templates and management

## Getting Started

1. Clone the repository:

```bash
git clone https://github.com/yourusername/acumen-chat.git
cd acumen-chat
```

2. Install dependencies:

```bash
npm install
```

3. Run the development server:

```bash
npm run dev
```

5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Usage

1. Access settings to add your API keys
2. Select your preferred AI model from the dropdown menu
3. Type your message and press Enter or click the send button
4. Your chat history and settings are automatically saved locally

## Technologies Used

- Next.js 14
- TypeScript
- Tailwind CSS
- shadcn/ui
- Vercel AI SDK
- Local Storage

## License

MIT
